컴파일러 기초
=

컴파일은 기본적으로 구문 분석 -> AST 생성 -> 최적화 -> 코드 생성 -> 링킹 과정으로 진행된다. 이 과정 중 컴파일러 프론트엔드가 담당하는 영역은 구문 분석 및 AST생성으로, 오늘은 이 과정이 어떻게 구현되는지 알아보려 한다.

### Tokenizer
어떤 구문을 토큰화하는 역할을 한다. 토큰은 어휘 분석의 단위이며, 문자, 단어, 단어구 등 의미있는 단위로 정해진다. 문자열을 토큰으로 분해하면 구조적으로 표현할 수 있어 처리하기 한결 쉬워진다. 자바의 StringTokenizer 를 생각하면 된다.

### Lexer
토큰의 의미를 분석해 분류하는 역할을 한다. Tokenizer와 Lexer가 하는 일을 합쳐서 Lexical Analyze 라고 한다. 보통 각 구문의 종류를 클래스로 표현하거나 enum을 사용해서 분류한 뒤 Parser에게 넘겨주는 듯하다.

### Parser
Parser 는 Lexical Analyze 된 데이터를 구조적으로 나타낸다. 이때 구문이 문법적으로 맞는지 검사도 진행한다. 이를 통틀어서 Syntax Analyze 라고 한다. 이 과정을 통해 만들어지는 자료구조가 AST이다. 구문을 트리로 표현하는 이유는 전체 구문이 쪼갤 수 없는 작은 구문들이 모여 중첩되면서 구성되기 때문에 계층 구조를 표현하기 좋은 트리를 사용하게 된 것 같다. 

AST가 어떻게 생겼는지는 [자바스크립트 AST 생성기](https://astexplorer.net/)를 들어가보면 잘 이해할 수 있다. 약간 문자열로만 존재하던 코드를 객체지향적으로 표현하면 AST가 되는 느낌이다.


<br>
<br>

튜링 완전하지만 가장 단순한 언어인 BrainFxxk의 프론트엔드를 구현하며 이해해보자.  
```
,         *h=getchar();   Read a character from stdin, 255 on EOF
.         putchar(*h);    Write a character to stdout
-         --*h;           Decrement tape
+         ++*h;           Increment tape
<         --h;            Move head left
>         ++h;            Move head right
[         while(*h) {     Start loop
]         }               End loop
```
언어는 8개의 문자만으로 구성되어 있다. 하지만 입출력과 반복문도 있어서 웬만한 건 다 할 수 있다.